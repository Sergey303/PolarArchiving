
# Система создания, поддержания, редактирования и публикации электронных архивов документов

Техническое название системы: Тургунда. Система может быть использована для формирования конкретных электронных архивов, репозиториев документов и электронных музеев. Система построена на фактографическом подходе, когда излагаются факты (документы, данные) в некоторой системе классов сущностей и отношений. Например, в архив помещается письмо как документ. Это означает, что вносится отсканированная электронная копия документа, заполняются поля о дате написания, авторе, получателе, возможно добавляются в базу данных упомянутые в письме персонажи, события, делается географическая привязка и т.д. Таким образом, пользователь электронного архива может не только посмотреть скан письма, но и получить довольно широкий спектр дополнительной информации и, пойдя по ссылкам, может узнать какие документы еще связаны с данным автором/получателем/персонажем, какая другая информация имеется про упомянутые организации, географические объекты.

Система поддерживает определенный набор мультимедиа документов, также допускает сохранение произвольных файлов и файловых сборок. Интерфейс Тургунды позволяет визуализировать и озвучивать основные форматы документов, а "портретное" изображение документов и сущностей, позволяет удобно представлять данные о них и об их связях с другими сущностями. 

Система предназначена для индивидуального и коллективного использования. Например, у вас есть множество документов (фотографии, видео, бумажные документы), которое хочется сохранить (навечно!). И вы помните или можете узнать кто, что, когда и почему отражены в документах. Вы вносите документы в архив и описываетет каждый из них. Хотя бы по-минимуму. Структуру документов можно сформировать ту, которая адекватна или близка их сути. Например, можно группировать документы по активностям, этапам жизни и творчества, по географии и т.д. Описание документов, свзяывание документов с персонами, огранизационными системами, географическая привязка дадут дополнительную струкутризацию документов и данных, внесенных в архив.

В случае коллективной и профессиональной работы по формированию архива, система позволяет выделять пользователей с разными ролями в отношении внесения и редактирования информации и управления коллективной работой.

## Hello World! Пример работы с системой
Для некоторого первичного знакомства с системой, можно поработать с тестовой системой. В ней есть некоторая случайно собранная информация и документы. Не бойтесь, вы ничего не испортите. Итак запускаем ресурс http://gea.iis.nsk.su/OATest

Данный ресурс чисто демонстрационный и  учебный. Для начала можно поискать что-нибудь. Поиск ведется по имени (Фамилия Имя Отчество для людей) или по его начальной части.  

## Разворачивание приложения Turgunda7 на сервере
Необходимо иметь дистрибутив (директория с файлами и поддиректориями), соответстующий платформе сервера. Напр. дистрибутив для Windows. Это делается через администартивную систему для IIS - Диспетчер служб для IIS. Необходимо под пулом приложений, относящихся к .NET Core, создать приложение, определив имя приложения (как вам нужно) и виртуальную папку (где дистрибутив). Обычно также надо определить настройти безопасности для рабочей подпапки wwwroot - нужно добавить группу пользователей IIS_IUSR и позволить чтения и записи.

При запуске этого приложения через Web, напр. http://localhost/имя_приложения
появится начальная страница, на ней может быть что-то неписано типа "Открытый архив СО РАН (редактирующее приложение)". Могут появиться и ошибки, тогда надо что-то исправлять. В случае корректного запуска, у вас появится приложение с пустой базой данных, с пустой базой документов, с отсутствующим списком редакторов и администраторов. 

Поскольку предполагается, что приложение устанавливает и первый раз запускает администратор системы, или лицо, выполняющее эту роль, надо провести еще некоторые мероприятия. Надо нажать на гиперссылку "ред" и потом нажать на "Регистрация пользователя", где зарегистрироваться под каким-то именем, указав пароль. Важно знать, что первый, кто зарегистрировался, автоматически становится администратором. Дальнейшие регистрации других пользователей будут присваивать им роль пользователя. Роль администратора может быть добавлена пользователю только администратором через специальные действия (см. далее).

Теперь можно потренироваться в работе с системой. В сущности, система представляет собой специальную базу данных. Можно создавать запись о сущности, можно редактировать запись о сущности, можно уничтожать запись. Список классов сущностей можно посмотреть в выпадающем меню (combobox) второго поля ввода. Если поставить серектор на пробел, то это "все". Для начала, полезно проверить что имеется в базе данных. Надо в режиме "все", просто нажать на кнопку "искать". Скорее всего, список объектов базы данных будет пустым. Попытки добавить объекты, скорее всего будут безуспешными. Дело в том, что распределенная база данных системы, размещается в так называемых кассетах. Кассеты - это специфические объекты, предназначенные для хранения документов и баз данных. Нет кассет, нет документов и данных. 

Администратору позволено создавать новые кассеты. Делается это по схеме: в поисковом интерфейсе задается имя новой кассеты, задается тип "Кассета", нажимается кнопка "искать". Если кассета с таким именем будет найдена, не стоит создавать новую с этим же, если не будет найдена, нужно нажать на команду [нов.]. Кассета будет создана и появится интерфейс редактироваия записи кассеты. Можно не торопиться использовать этот интерфейс и снова вернуться к кнопке "искать". Теперь ее нажатие уже выдает один элемент, это собственно кассету, которую мы создали, нажатие на эту ссылку выведет нас на редактирование записи о сущности, в данном случае, на редактирование записи о кассете. Не торопитесь редактировать кассету, давайте сначала освоим просто редактирование любой сущности. Что это значит? Еще раз посмотрите набор классов сущностей. Это персоны, организации (организационные системы), фото, видео, аудио и просто документы, коллекции, географичесие понятия и некторые другие. 

###TODO: я убрал в ApplicationProfile0.xml неправильную сущность collection-member, добавленную Алексеем. Надо проверить правильность и распространить изменение на места использования.

Поучимся. Введем новую сущность, напр. персону. Для этого, через выпадающее меню определим класс сущности "Персона" и зададим желаемой имя или его начальную часть. Например, поищем персону "Пупкин". Наберем без кавычек имя и нажмем "искать". Естественно, такой сущности пока нет, что и будет неявно сказано, но появится команда [нов.], нажмем ее, сущность (персона) будет заведена и мы перейдем в интерфейс просмотра/редактирования записи. Если повнимательнее посмотреть на информацию, то легко обнаружить, что она состоит из класса сущностей (Персона), некоторых заголовков курсивом, строчки с именем персоны и далее идет разделы, о которых можно будет узнать далее. Собственно запись - одна строчка, которая пока содержить только имя. Нажмем команду ред (редактировать) в этой строчке. Одна строчка преобразуется в вертикально расположенную таблицу поле-значение. Поле имя уже заполнено, остальные - нет. В данной системе не обязательно заполнять все поля, жалетельно заполнить те, информация о которых у вас имеется. Например, отредактируем первое поле до канонического ФИО, я набрал Пупкин Василий Васильевич, дату "рождения" 1983-04-01 и поле описания типа "Персонаж анекдотов эпохи застоя". При нажатии "записать!", информация будет записана в базу данных и отобразится в интерфейсе в одну строчку. Причем сверху расположены имена полей, а в основной строчке значения этих полей. 

В некоторых редакторах фиксация результатов редактирования не происходит, напр. в Internet Explorer, рекомендуем использовать Google Chrome. 

Двинемся дальше. Как всегда, можно посмотреть список имеющихся в базе данных сущностей, теперь их уже две. И видно, что каждая отмечается своим классом и именем, оформленным как гиперссылка. Аналогично вводятся и редактируются и другие сущности. Теперь важно освоить связи между сущностями и их редактирование. Напр. между персоной Пупкин и организацией "Смешная организация" мы бы хотели установить связь. Для этого, перейдем, напр. через поиск, на запись Пупкина и обратитм внимание на пока не заполненный раздел "участник в орг.". Нам нужен новый участник, нажимаем [нов] этого раздела. Появляется форма редактирования участия. В ней - пока не заполненное поле "в орг. сист.", роль и др. Наберем название желаемой организационной системы "Смешная организация" и (внимание!), нажмем кнопку "пров" - проверить. Это нужно для проверки имеется ли такая организация в базе данных или еще нет. Мы получим пустой список, как всегда, нажмем [нов]. А затем уже нажмем "записать!". Организация будет создана и связь между Пупкиным и организацией также будет установлена. Теперь можно нажать на гиперссылку организации и переместиться в ее запись.  

На самом деле, выходя на ту или иную сущность, мы видим не только ее запись, но и связи этой сущности с другими. Нажав на гиперссылку, мы удидим и запись организации и то, что там есть работник/участник Пупкин. Такой вид представления информации мы называем информационным портретом сущности. В зависимости от класса сущности, информационный портрет выглядит по-разному. Изменяются поля записи для разных классов сущностей, изменяется набор и смысл отношений. Кроме бинарных отношений сущность-сущности, есть и унарные "отношения", устанавливаемые для сущности. Вернемся к портрету Пупкина. Раздел "именуется" как раз представляет альтернативное имя персоны. Создадим новое отношение, нажав (как всегда [нов]), введем другое имя напр. Вася. Как ни странно, люди меняют свои имена, фамилии (особенно женщины), отчества, могут быть варианты имен на других языках и т.д. Как и других отношений, дополнительных имен может быть несколько. Другой вариант унарного отношения: степень/титул. Имеется ввиду научные и др. степени, напр. доктор биологических наук, звания - профессор, заслуженный деятель науки, академик и титул - князь, граф, барон, сэр, пэр и др.

Теперь вы уже без труда справитесь с установлением отношения типа "проживание" Пупкина с каким-то географическим объектом. В результате Выших усилий довольно быстро может начать появляться база данных, отражающая какие-то знания о реальности или придуманности. 

Теперь перейдем к документам. Документы являются тем, что предлагаемая система архивирует и являются основой фактографического подхода. Документ - это целостная информация, зафиксированная на каком-то носителе. Мы работаем в основном с цифровыми документами или с цифровыми копиями документов. В узком смысле, цифровой архив - склад таких документов. Это могут быть фотографии, сканы документов, видео, аудио, документы в специальных форматах doc, pdf, rtf, html и др. У документов - два "лица". С одной стороны, это цифровой контент, в конечном итоге, набор байтов и способ интерпретации этих байтов. С другой строны, это запись в базе данных, это сущность. У документа может быть имя, дата создания, автор или авторы, получатель. Документ отражает какие-то сущности реального мира - людей, организационные системы, географические системы и даже другие документы. 

Попробуем сформировать документ. Рекомендуемый нашими информационными специалистами способ - берем "страницы книжки", формируем из них "книжку" и описываем ее. Проще всего, мыслить сканами страниц книжки. Представим, что у нас есть набор сосканированных страниц какого-то документа ("книжки"). Начнем с того, чтобы ввести в архив сканы страниц. Для пробы - это могут быть любые картинки (имиджи), имеющиеся на вышем компьютере. Ввод картинок в архивную систему осуществляется как загрузка (upload) в конкретную кассету перечисленных пользователем файлов. Мы пока завели одну кассету, в нее и будем загружать. Это делается через страницу кассеты. Задаем в поисковом интерфейсе класс "Кассета", нажимаем на поиск, находим кассету переходим на ее портрет. Теперь внимательно посмотрим на формы, находящиеся перед портретом. Это только для кассет. Первая однострочная форма - загрузка файлов в данную кассету. Нажмем на "Выбрать файлы", найдем на компьютере условные сканы, напр. любые картинки в разделе "Изображения", отметим их и нажмем "Открыть", а потом кнопку Upload. Картинки попадут в коллекцию под названием upload. Если имена файлов были правильно отсортированы, напр. лексически увеличивалися с ростом номера скана, то и в коллекции они будут располагаться в нужном порядке, если нет, то придется искать следующую сраничку для обработки. Выберем первую страницу, перейдем на нее. В ее информационном портрете есть имя файла, используемое в качестве имени страницы и есть отношение принадлежности страницы папке "upload". 

Рекомендуемая методика дальнейших действий заключается в заполнении отношения "содержится в", нажмем на [нов]. 

Заведем новый объект класса "документ", пусть это будет как-бы книжка. Как всегда, заведение сущности делается через поисковый интерфейс, указав класс сущности и имя сущности. Классом у нас будет "Документ", имя, напр. "Книжка в картинках".  

## Документация по работе с системой Тургунда (Turgunda7)

Исходный вариант (текст) системы находится в репозитории https://github.com/agmarchuk/PolarArchiving в виде решениия (Solution) для VisualStudio или .NET Core. Для его применения сначала надо "изготовить" бинарный дистрибутив для конкретной платформы. В данном случае, предполагается платформа Windows-7/10 с 64-разрядной архитектурой. Изготовление дистрибутива будем выполнять в .NET Core, для этогоо удобно использовать Visual Studio Code https://code.visualstudio.com/?wt.mc_id=DX_841432. Естественно, также надо иметь установленным пакет .NET Core https://docs.microsoft.com/ru-ru/dotnet/core/ версии  2.1 или выше.

В решении PolarArchiving находим проект src\Turgunda7. В решении также  должны присутствовать проекты CassetteCore и TurgundaCommon. Также используются через Nuget компоненты PolarDB. Все указанное должно подключиться автоматически (PolarDB - при наличии фукционирующего Интернета).

Параметры изготавливаемого дистрибутива задаются в конфигураторе, в частности, в разделе
```
  <PropertyGroup>
    <TargetFramework>netcoreapp2.0</TargetFramework>
    <OutputType>Exe</OutputType>
    <RuntimeIdentifier>win10-x64</RuntimeIdentifier>
  </PropertyGroup>
  ```
См. документацию .NET Core по установке и публикации. 

В директории src\Turgunda7 запускаем 
```
dotnet publish -c Release
```
Если все правильно, то "где-то в глубине", скорее всего в директории bin\Release\netcoreapp2.0\win10-x64\publish, буде создан образ, которы можно перемещать и запускать. "Заберем" эту директорию переместив куда-нибудь или, для начала, будем работать с ней в указанном месте. Для информации: там загрузилось много модулей кода, создано приложение Turgunda7.exe, есть web.config (это все же  web-приложение!), есть директория Views с "остатками" вида страниц, есть папка wwwroot -  рабочая область приложения, там есть важные для приложения файлы и там будут создаваться файлы и директории. В принципе, все это знать необязательно, важно уметь запускать приложение - тот самый исполняемый файл Turgunda7.exe. Можно сразу его запустить. 

Брандмауэр может "ругнуться", но если вы хотите поработать с системой, то разрешите запуск этого приложения, в дальнейшем, брандмауэр учтет ваш выбор и ругаться не будет. В окне запуска приложение, которое останется на экране можно прочитать, что приложение запущено, и ждет клиента на данной машине по но меру порта 52018. Наберите http://localhost:52018, появитсяя интерфейс приложения. 

Обязательно надо зарегистрироваться и войти через вход ред (редактировать) - первый зарегистрировавшийся автоматически становится администратором данного экземпляра системы и данной базы данных. Пока база данныых - пустая. Следующее обязательное действие - создание кассеты в базе данных. 

### 20181219 14:52
В прошлый раз я застрял на некоторых непродуманных обстоятельствах.

Первое. Дистрибутив Тургунды переносится только без локально созданных кассет. Здесь теоретически можно было бы начать внедрять относительные имена файлов, но что-то есть сомнения. Путь будет так. А дистрибутив надо делать или без директории для кассет или без кассет. 

Второе. С универсальной последовательностиью надо что-то делать. Одно из действий - сканирование элементов. Если есть только признаки isnull и mT, эффекттивное сканирование организовать трудно. Можно по индексу ключа пробежаться, то это будет "дергатня". Можно добавить еще однин признак unused, истинность которого значить неиспользование данной записи. Но нужен ли тогда отдельный признак isnull? Если все элементы заданного ключа помечены unused, в результате элемент по ключу будет ненайден. Однако, рано "хоронить" isnull. Он необходим в распределенной системе - "занулили" в одной секции, получили результат везде, а не только в этой секции. Итак, три признака - один длинное целое и два булевских. Можно как-то побитно разметить отдельный байт. Теперь сканировать понятно как. 

Третье. Оказалось, что пока реализации такого подхода нет. Совсем нет. Есть какие-то заготовки в пространстве имен Polar.DB, но целостного решения, тем более - библиотечного решения пока нет. Посмотрю как я использовал эти заготовки в Polar.Datanode. Попробую написать программу. Расширю GetStarted на новый эксперимент Program12.

Что-то написал. Последовательность записей, состоящей из целого ключа, строкового имени и вещественного возраста, создается в количестве 100 млн. записей. Создается индекс, состоящий из массива ключей и массива офсетов. В тесте - это несколько больше, чем 3 Гб. Выборка по случайному ключу: 80 мс. / 10 тыс. Вполне прилично. Но индекс пока разворачивается в массивах.  

### 20181220 07:53
Вчера поработал над универсальной последовательностью. Пока провел эксперимент, когда завел последовательность и индекс к последовательности и тестирую ввод и скорость выборки по ключу. Получается неплохо.   

Ввод и построение индекса для 10 млн. элементов выполняется за 10.8 сек. (домашний компьютер), 10 тыс выборок - за 64 мс. Можно несколько ускорить ввод, для этого не нужно перекидывать индекс туда-сюда. В принципе, политика использования оперативной памяти должна определяться динамически исходя из размеров задачи и выделенных ресурсов. Буду считать, что задача среднего размера (до 100 млн. элементов) и ресурсов достаточно для сортировки в ОЗУ. 

Теперь, индекс сначала накапливается в массивах, потом сортируется, потом записывается в потоки. Получилось: загрузка 7 сек., выборка 10 тыс. 65 мс. Следующий шаг определить существенно ли влияет бинарный поиск ключа на скорость.  

Влияет, но не сильно. На 10 млн. элементов получилось 56-57 мс. / 10 тыс. выборок
100 млн. как-то опять не получилось. Загрузка выполнилась довольно быстро за 82 сек., но потом программа видимо замедлилась и скорость выборки даже неприлично воспроизводить. А на 50 млн. элементов - все в порядке. Загрузка 36 сек., выборка 72 мс. и 60 мс. для полного и тестового (только чтение из последовательности) вариантов. В режиме toload=false получилось: 74 и 59.

Теперь попробую отказаться от повторного использования массива офсетов. Время ровно удвоилось, что логично... Теперь надо посмотреть сработает ли на 100 млн. 
```
10 млн.
7 сек., 121 мс., без загрузки 120-122
50 млн.
25 сек., 126 мс., без загрузки 126-128
100 млн. 
46 сек., 71 сек., без загрузки 56 сек... 
50 млн.
21 сек., 159 мс., без загрузки 127-129
100 млн. 
49 сек., 59 сек., без загрузки 39 сек... 

На рабочем (16 Гб ОЗУ)
100 млн. 
49 сек., 150 мс., без загрузки 142 мс. 
200 млн. 
99 сек., 157 мс.
400 млн.
350 сек., 222 сек. увы... 
```

### 20181221 02:00
Что-то не спится. Наверное потому, что рынок "валится", а я не знаю что делать... Решил поработать.

Что я сделал и чего не сделал? Во-первых - концепция. Есть некоторые нюансы, а так вроде уже что-то получается. Есть некоторая выделенность ключа, но в этом есть смысл. Смысл заключается в наборе редактирующих действий. Действительно, нужна полнота операций редактирования. То есть такие средства, чтобы можно было бы через элементарные действия перевести любой корректный набор элементов в любой другой. Очевидно, что эти действия - добавление и уничтожение. Но если добавление делается совсем просто, то для уничтожения надо иметь указатель того, что уничтожается. Пусть это будет ключем. Не столь очевидным является предположение о том, что ключ позволяет выстраивать индекс. Вроде "да", потому что и добавление и уничтожение должны делаться быстро. Но может и "нет", поскольку указатель на элемент может нарушать логику набора элементов (множества), напр. может быть каким-то офсетом. Тогда должны присутствовать операции выделения, когда по какому-то индексному построению запрос на выделение дает набор координат (офсетов). В общем, лучше в эти "дебри" не уходить, а остаться в рамках простых рассуждений. 

Итак, элементами концепции являются: 
1) множество или набор элементов;
2) ключевое значение у элемента;
3) временная отметка;
4) признак isnull;
5) признак unused.

Комментарии. По первому пункту, элементы - из множества возможных элементов. Часто - типизированные. У набора отсутствует определенный порядок и они могут быть произвольно переставлены. Все элементы попарно различные, это положение можно нарушить, но так проще. Среди элементов набора могут быть используемые и неиспользуемые. В результате воздействия на набор, некоторые используемые элементы могут превратиться в неиспользуемые. Но не наоборот. У набора есть "грязный" перечислитель элементов - это некоторый способ "выдачи" значений элементов в виде потока, причем выдаются все элементы и каждый - один раз. Можно предположить существование функции unused(element) определяющей используется элемент или нет. В принципе, такай функция кажется необязательной, но вроде с ней проще. Например, уже на этой стадии абстракции, можно отфильтровать из "грязного" потока неиспользуемые элементы и получить поток всех используемых. 

На элементах есть однозначая функция ключа, переводящая элемент в значение специального вида или типа. Этот вид или тип должен быть сравнимым на равенство и, в сложных случаях желательно, чтобы у него была хеш-функция, помогающая вычислять равенство элементов. Примером сложного случая может быть набор триплетов. В базовой семантике RDF триплеты совпадают если совпадают его части (субъект, предикат, объект). 

Я вот подумал, что признак unused не очень удобен. Действительно, мы добавляем элемент в набор и обязаны не только проверить набор на наличие старых элементов, но найти и отметить последний. Надо будет подумать по этому поводу. 

Кроме функции ключа, нужно ввести еще отметку времени. Отметак времени mT "вставляется" в элемент и служит для определения оригинала среди элементов. Все элементы с одинаковым ключем считаются разными "версиями" одного элемента и в выходном потоке или по действию get(key) выделяется тот из них, который имеет большую отметку по времени. При одинаковой отметке, берется произвольный. Почему так, а не как-то иначе? Одно из возможных объяснений заключается в том, что элемент можно быстро "положить" в (распределенный) набор, а потом уже разбираться в том, какой из элементов является оригиналом. При этом, допустимо использовать какую-то из предыдущих версий. "Уничтоженный" элемент в этой модели - не исключение. Семантика уничтожения определяется том, что можно сгенерировать элемент с заданным ключем, но дающий true на функции isnull(element).  

Уже укажывалась проблема, связанная с (только) временной отметкой. Это трудности организации сканирования элементов последовательности. Можно сканирование делать через индекс по ключу, если он позволяет, но это будет так медленно... Есть еще подход к сканированию. Можно выделить все неопределенные элементы в один набор. Как-бы изъять оттуда, где они были. Хотя физически изымать не обязательно. Этот набор сделать в виде однозначной таблицы. И тогда сканирование будет заключается в "грязном" сканировании, но все элементы проверяются на наличие в этом специальном наборе.

### 20181222 09:47
Что-то я застрял на концепции и отметках. Я вот что подумал: много зависит от парадигмы. Если считать, что новый айтем может быть помещен в любой набор - это одно, если набор предопределен - это другое. А еще я подумал о том, что временная отметка лучше соответствует семантике состояний. Я имею ввиду то, что мы можем говорить об изменении состояния базы данных. Изменение локального набора с указанием временной отметки - действие "мгновенное". Изменяется состояние только одного айтема. Если его рассматривать распределенно, то все значения айтема корректны в пределах какого-то процесса. Если это учитывать в программе, это может быть ключом к корректному решению разных задач. 

Я решил, что для прогресса в модели, нужно рассмотреть интеграцию отдельных моделей в общую. Например, есть множество отделльных и распределенных наборов, а требуется сделать корректно работающую общую базу данных. Исходный посыл уже фигурировал ранее. "Сливаются" айтемы, имеющие один ключ. По смыслу, "сливаются" они не полностью, а все становятся "одинаковыми". То есть, использование любого считается корректным. Это, конечно, УЖАСНОЕ предположение, но что поделаешь... Для компенсации предположения, можно постулировать, что некоторый синхронизационный процесс "нормализует" базу данных таким образом, что постепенно, возможно в течение определенного времени, при отсутствии новых записей, выбираемые из любой точки данные станут последними записанными. Как-то так...

Предположим, что все наборы обладают необходимыми качествами. Точнее не только сами наборы, но и локальные базы данных, построенные на их основе. Нужен какой-то новый термин для локальной базы данных. Какие качества мы имеем ввиду? Вот те самые. Все элементы доступны и запрос элемента по ключу дает последнюю его модификацию. Последнюю в локальном смысле. Идея процесса установления также неоднократно обсуждалась. Мы посылаем запрос get() всем. Кто-то на него отвечает. По предыдущим рассуждениям, этот ответ рассматриватеся как корректный. Дальше организуется "волна" по доставке оригинала айтема туда, где эхтот айтем  также присутствует. Другой вариант: волна "смывает" варианты айтемов, которые перестают быть актуальными. 

Такое устройство локального хранилища и их интеграции, в нашем "кассетном" варианте выглядит следующим образом. Есть ряд фог-хранилищ, у каждого свой владелец или это отдельное "ведро". А есть еще кеш общих данных. Вот это последнее выглядит сомнительно. Кеш - это значит можно уничтожеть. Но тогда семантика "согласованность в конце концов" потрадает. И даже если не кеш, то мы меняем конфигурацию и снова получаем несогласованность. Надо возвращаться к модели. 

### 20181224 16:31
Возвращаюсь к модели. Когда одно локальное хранилище - более или менее все понятно. А вот если есть много, хотя бы 2. Тогда для получения записи, придется опрашивать все хранилища или хотя бы избранные. Вот здесь - самое критическое место. Опрашивать все "дальние" хранилища по каждому запросу - не эффективно. Можно поступить следующим образом: опрашивать "ближнее", если там есть - выдавать. Если нет - искать дальше. Но и выдав значение, не нужно "успокаиваться", надо волну запросов продложнить в попытке найти более "свежее" значение. Даже не знаю что сказать по этому поводу. Мне кажется, раньше была конструкция эффективнее. Эта конструкция базировалась на распределенном реплицировании. В этом случае, "волна" запросов порождается не при чтении записи, а при записи. Запись (записей!) производится как правило реже чтения. На этом можно сэкономить. 

Еще можно было бы "поколдовать" с разделами. Если хранилищу приписать набор признаков, то возможны варианты. Самым простым вариантом является однозначное направление оператора чтения/записи соответствующему разделу. Но так мы лишаемся преимуществ кассетной организации и внешнего редактирования элементов. А какие могут быть варианты?

Сейчас в кассету погружаются файлы локальных определений - фог-файлы. У каждого фога есть своя префиксная составляющая. Пользователь пишет в "свой" фог-файл. Соответственно запрос по ключу может быть локализован конкретным фогом. Теоретически, можно обеспечить свойство такое, что абонент пишет только с одной группой идентификаторов. Например, можно использовать именование, датирования и reification. Может быть... Но и не обязательно.

### 20181225 12:00
Я серьезно застрял на модели. В принципе, сосредоточенная модель key-value базы данных мне понятна. И даже с элементом пользовательских секций (разделов). Не удалось развить эту модель до распределенного варианта. А так было привлекательно: есть кассета, есть ее локальная база данных, которая легко интегрируется с другими кассетами и их базами данных. Думаю, что еще можно будет подумать в этом направлении... Но вернемся на землю. Что нам нужно? Работающая база данных для Тургунды. И пока сосредоточенная на едином сервере, на котором создается сервис информационной базы. В информационную базу входят собственно файлы контента (документы и др.) и база данных. В дальнейшем, можно будет "загнать" всю информационную базу в один файл (легко!..).

Итак, что такое "стандартная" модель последовательности? 
1) Это набор элементов определенного типа. Ее можно обнулять, можно пополнять, ее можно сканировать. Состояние последовательности включает в себя число элементов, которое нужно синхронизировать Flush(), сами элементы, указатель позиции чтения/записи offset. Если указатель стоит на элементе, можно читать элемент, в некоторых случаях, писать элемент. Если указатель стоит за последним элементом, то можно писать элемент.  
2) В некоторых случаях (если элементы фиксированного размера), можно делать выборку или запись по индексу. К key-value это не имеет прямого отношения, но все же можно отметить эти свойства. 

Следующий уровень абстракции - упорядоченность элементов. Упорядоченность достигается тем, что между элементами задается отношение CompareTo(). Соответственно, отношение удовлетворяет некоторым аксиомам метрики. Можно отсортировать поледовательность по этому отношению, т.е. построить новую последовательность, в которой элементы с меньшим номером, "меньше" по заданному отношению. В принципе, процедура может быть не слишком дешевой, поскольку в общем случае требует lg(N) сканирований. Но в некоторых случаях, такая процедура нужна. 

Другой способ реализации упорядоченности заключается в построении набора офсетов такого, что Element(off1).CompareTo(Element(off2)) <= 0 если off1 < off2.   
 
Пусть в последовательности появляется ключ. Ключ - типизованное значение, вычисляемое на элементах последовательности через ключевую функцию.  

### 20181227 07:57
Я все "подкрадываюсь" и "подкрадываюсь" к модели и спецификации. Думаю, что итог будет довольно сильно походить на универсальный индекс в разделе Polar.CellIndexes. Только не будет "стандартных" ячеек, будет изменена конструкция айтема (не будет "конверта" с признаком уничтожения) и, видимо, будет явно прописана отметка времени. Кроме того, надо будет сделать "большую сортировку" и "большое упорядочивание". Как-то так...

Итак, есть простая модель последовательности типизованных элементов. Можно добавлять, можно сканировать. Если фиксированный размер элемента, то можно читать или записывать по произвольному индексу. Можно получать офсеты, можно читать по офсету, можно писать по офсету, если это последний (начало свободного пространства). Где-то я это писал. Важно, что это всего лишь полуфабрикат. А может и нет? Вроде есть две "полуфабрикатные" позиции: текущий указатель Position и количество элементов в последовательности, которое фиксируется.

Сейчас посмотрел код класса UniversalSequenceBase. Вроде все правильно. Есть сомнения в реализации AppendElement(object v) - не очевидна диагностика ошибок в использовании (!). 

Следующий уровень модели: класс UniversalSequence<T> where T: IComparable;
Где T - тип значения ключа, соответственно, вводится функция ключа.
Реализация на первый взгляд непонятна. Вроде класс определен для уже подготовленных последовательностей ( // Предполагается, что есть некоторый ключ и последовательность отсортирована по этому ключу). И там есть варианты бинарного поиска. Введена функция 
```
public Func<T, Diapason> getDia = null; // Задать можно снаружи (???)
```
но она не используется... 

Еще есть сомнение в том, что сразу надо "резко" вводить ключ. Мы пропустили этап с функцией сравнения. Кажется, надо вернуться к разбивке типа той, что есть в CellIndexes. Посмотрю код. Посмотрел, как-то не слишком прозрачно... 

Последовательность модельных расширений следующая:
а) база универсальной последовательности
б) Основные виды индексов
в) key-value последовательность

А формировать решения можно попробовать на экспериментах. Воспользуемся фототекой. По крайней мере, первой таблицей. Вернулся к уже реализованному тесту Program12. Создаю последовательность в 4 млн. записей. Делаю еще две последовательности - ключей и офсетов. Загрузка и вычисление индекса выполянется 1.8 сек. А скорость выборок 110 мс. на 10 тыс.

Переделал тест на использование UniversalSequenceBase. Загрузка 1.2 сек. или несколько больше. 

### 20181228 11:13
Действительно подтверждено, что те действия, которые я выполнял с UniversalSequence можно выполнять и с базой. А в UniversalSequence дополнитлеьно есть только параметризация, пара функций и мало полезный public object GetAny(long start, long number, T key). Почему малополезный? Потому что по модели выявления оригинала, нужно выделение всех, а потом фильтрация.

Теоретически, все эти "штучки" можно объединить в один класс. Но чтобы этот класс был полезным, надо ограничить возможность выхода на сложные ошибки. Создание экземпляра, равно как подсоединение к экземпляру, выглядит надежной группой действий. Clear() - да, Flush() - да. AddElement() - тоже похоже "да". И даже сканирование Scan(), также выглядит достаточно надежным действием. Эффекты синхронизации я пока не понимаю...

Попробую пойти по пути, намеченному в Polar.CellsIndexes. Можно даже позаимствовать имена, только в другом пространстве имен.  

Начал что-то создавать и "уперся" в абстракцию индекса. Ну чтобы интерфейс специфицировать. 

### 20190101 09:22
С Новым годом! Что-то концовка года была нервная, но теперь есть неделя (8 дней) на то, чтобы поработать. 

Начну с уже продуманного. Оказалось, что не видно способа избавиться от признака deleted в опорной таблице. Действительно, общая форма выборки - это:
```
sequence.Where(e => P(e)).Select(e => F(e))
```
Чтобы проводить фильтрацию и функциональное преобразование, надо делать качественное сканирование. А при сканировании мы должны выделять только "действующие" элементы. Другого эффективного способа кроме вставления признака deleted как-то не получается... Похоже, признак и отметка времени являются не альтернативными свойствами, а дополняющими. Признак важен для сосредоточенной части модели, а отметка времени - для распределенной. Вернусь к модели.

Итак, есть набор элементов одного типа. В этот набор можно добавлять элементы, Элементы можно сканировать, т.е. перебрать по очереди все элементы. Вот сканирование подозрительно в контексте множества совпадающих по ключу элементов в разных сегментах.
На элементах определены функции key(e), mT(e), isnull(e), deleted(e). Элементы с признаком deleted считаются уничтоженными и не участвуют в выходных выборках. Элементы с одинаковым значением key(e) считаются "одинаковыми" и правильным представителем является элемент с максимальной отметкой времени mT(e). Элемент с истинным isnull(e) соответствует "совсем" уничтоженному элементу.

Насчет сканирования я подумал. Замечательным свойством может быть, когда ключи элементов "распадаются" по сегментам. Тогда не требуется дополнительного сведения одноключевых элементов. В этом случае, отметка времени не нужна! Но если это свойство не соблюдается, то как-то плохо...

Причем плохо во всех вопросах. Работа с множеством пересекающихся сегментов может выполняться через кеширование данных. Если имеется ситуация внешних сегментов, то можно делать запросы к этим сегментам и множества результатов накапливать в кеше корневого сегмента (хранилища). То есть, если айтема с заданным ключом нет в кеше, он запрашивается везде, где он может быть и помещается в кеш. Надо все это внимательно обдумать. 

### 20190102 10:13
В общем, откладываю идею "настоящей" распределенности, т.е. распределенной системы сервисов, и начинаю сосредотачиваться на сегментном решении.

Придется вернуться к варианту UniversalSequence, наследуемого от базы. Так раньше "работало", надо посмотреть новый вариант. Универсальная последовательность - структура прямолинейной реализации. Просто последовательность. Есть ключ, есть другие оговоренные свойства и функции. Но как же делать простейший Fill()? Просто "бездумно" пишем поток элементов в последовательность (это надо для скорости). Видимо так, но потом придется возвращаться к этому потоку. Мы вычислим ключевой индекс. Ключевой индекс даст нам совпадения. В предположении, что совпадений мало, мы можем по каждому совпадению, не являющемуся оригиналом, сделать специальную отметку unused. Другие индексы не будут влиять на опорную последовательность. Как-то я об этом не думал раньше...

Появляется еще один вопрос о технологичности нахождения оригинала. Индекс содержит массив офсетов и, в лучшем случае, ключ или полуключ. Проходить весь массив офсетов, прыгая по последовательности, кажется слишком затратным. Итак - только ключ или полуключ! А вот простой индекс может быть и view-ориентированным. 

### 20190103 09:36
В уме я все расчитал, надо эти мысли "положить на бумагу". Если коротко, что универсальная последовательность очень проста: это последовательность и набор индексов. Набор индексов отрабатывает действия, проводимые с последовательностью. 

Промежду делом, провел простенький эксперимент с текущим (быстрым) вариантом ключевой последовательности. Я заменил файл на MemoryStream. Загрузка выполняется приблизительно столько же, а выборки - раз в 6 быстрее - 10 мс. на 10 тыс. А если избавиться от бинарного поиска, то будет 34 мс. на 100 тыс. выборок. Вполне прилично... Есть к чему стремиться!

Вернусь к постепенному формированию универсальной последовательности с индексами. Строю одну последовательность и один ключевой индекс. Пытаюсь все сделать правильно. 

### 20190104 07:41
Двигаюсь очень медленно. Но двигаюсь. Кажется...

Сейчас поизучаю вопрос буферизации. Дело в том, что пишется два потока. Вроде все нормально - это два файла, но как-то нет уверенности, что с кешированием все в порядке. 

2 файла заполняются 4.5-4.8 сек. Один - 2.8-2.9 сек. Вроде так и должно быть. Подозреваю, что буферизовать нужно при работе с одним файлом и несколькими потоками. 

Под конец дня понял, что я неправильно структурирую решение. Наиболее простое решение - один класс, напр. Sequence и сразу в конструкторе указаные индексы, указаны в виде массива разных классов, имеющих интерфейс IIndex. Что-нибудь вроде:
```
Sequence usequence = new Sequence(tp_element, stream_gen, 
    new IIndex[] 
    {
      new IndexKey(keyProducer, stream_gen),
      ...
    }
);
```
Причем IndexKey - это уже динамический индекс. Простая последовательность будет отрабатывать добавления и изменения элементов, а индексы - доступ к элементам. Нулевым членом в последовательности может быть или должен быть основной ключевой индекс. Он может быть или IndexKey или IndexHalfkey. Неключевой индекс IndexView используется когда нет ключа, напр. для поиска по имени. Еще в обойме индексов должен быть секторный индекс, но по его поводу я задумаюсь позже. 

### 20190105 11:44

Есть одна "загвоздка" - нет схемы управления стримами. Например, надо разделить стримы на группы или что-то поддержать кешевым решением и др. Еще одна скрытая "загвоздка" заключатся в том, что и порождение стримов и подключение к стримам осуществляется с помощью одного генератора. Рассмотрим отдельно эту проблему. Некоторым базовым представлением является уже сформированный набор стримов с заданными свойствами, тогда остается только подставлять следующее значение в следующее использование. Все бы ничего, но мы на стадии конструирования универсальной последовательности не очень представляем предназначение тех или иных стримов. Более того, схема, как и базовая, (сильно) зависит от порядка использования стримов в процессе разворачивания, а он может различаться по создании стримов и при их использовании. Итак, что можно сделать?

Оставлю этот вопрос на будущее. В конце концов, я могу подобрать нужные стримы в вектор и организовать из него генератор. Попробую написать код. 

Что-то написал, пока очень мало. Можно сказать, что сообразил, что управлять стримами возможность имеется. Действительно, в приведенном примере описания объекта usequence, генераторы стримов могут быть разными и управление ими ведется в общем контексте. Так что продолжу. 

Сделал последовательность с одним ключевым индексом. Вычисляется 2 файла, вроде нармальных размеров. Надо попробовать что-то прочитать. Время формирование последовательности и индекса 4.5 сек. для 10 млн. элементов. 

### 20190106 11:46
НА чем я вчера застрял. Вообще-то на том, что надо реализовывать сортировку и бинарный поиск. Некоторой альтернативой стало то, что ключевой индекс, как и некоторые другие, можно реализовывать и как последовательность записи, состоящей из офсета и ключа или как пару последовательностей офсетов и ключей. Решил, что пока идейнее будет реализовать классический вариант - одна последовательность записей. Сами действия можно поместить в  UniversalSequenceBase. Попробую, там еще проблемы с типом ключа ожидаются.

Что-то не очень хорошее произошло с размером индексного файла f2. Его размер 198 888 898 байт.
А должно быть 10 млн. * 12 байтов + 8 !!! 

Выяснил. Просто за счет иерархии построения, f0 оказался индексом, а f1 - опорной таблицей. 

### 20190108 02:58
Вчерашним днем юбыл занят изучением диссертации Артамоновой. Теперь уже ночь и вообще наступили новые сутки...

Я не закончил делать индекс, а надо бы. Надо сделать универскльное ключевое решение, а потом специализированное. Начну с универсального. 

Сортировка вроде заработала, но скорость существенно хуже, чем была. Сейчас она 8.5 сек. Секундочку... Похоже, все не так плохо. Я изменил режим компиляции на Release и получилось 4.8 сек. и даже в одном из пропусков 4.5 сек. Наверное память расходуестя изрядно... Попробую увеличить количество элементов. Увеличил до 100 млн., все сработало, вроде бы, и за 64 сек. Только я не понял что творится с использованием ОЗУ. Попробую перезагрузиться в запустить на более "чистой" машине. 

200 млн. - 170 сек.
400 млн. - 323 сек.
800 млн. - не хватило дискового пространства, провожу эксперимент на рабочем компьютере

800 млн. элементов на набочем компьютере обрабатывались 1877 сек. Похоже, это уже на грани. Попробую 400 млн. - 895 сек. 

### 20190109 07:51
Забавно, но построение базы данных на рабочем компьютере выполняется заметно медленнее, чем на более слабом домашнем. 100 млн. элементов строятся 86 сек., 128 сек., 113 сек. А 200 млн. - 445 сек. Странно.

Я остановился на том, что мне нужен бинарный поиск в индексированной последовательности. Для простого случая, с которым я сейчас работаю, надо из индекса сформировать поток офсетов всех элементов удовлетворивших кортерий совпадению ключей. 

### 20190110 10:32
Наконец, сдела бинарный поиск. Удалось его променить. На рабочем компьютере 10 млн. записей загузились за 9 сек., 10 тыс. выборок по ключу выполнялись 1100 мс. То есть, раз в 10-20 медленнее, чем при использовании специального индекса или без оного. Собственно, результат ожидаем. По и дихотомии, 10 млн. точек делятся пополам приблизительно 23 раза. А каждое деление - это обращение к диску или кешу диска. В данном случае - к кешу, поскольку на "чистой машине" запросы выполнялись бы раз в 1000 медленнее.

На домашнем компьютере этот же текст показал также 9 сек. на загрузке и также 9-11 сек на выполнении 10 тыс. запросов. 

Перешел на работу, теперь изменения будут проводиться только рабочего компьютера. Пропуск стандартных 10 млн. записей дал время щагрузки 8.8 сек., но вото 10 тыс. выборок по-прежнему несколько больше 1000 мс. Теперь надо попробовать запустить без загрузки. 

Сечас пропустил тест на 100 млн. в режиме отладки, получилось 198 сек. загрузка, использовано 13.6 Гб., 236 сек. / 10 тыс. выборок.
В рабочем режиме, получилось загрузка 158 сек., выборки 236 сек.
Без загрузки, выборка получилась 56 сек. Так что между 10 и 100 гигабайтами, есть предел для данной схемы и 16 Гб. ОЗУ. Буду проводить эксперименты на 10 млн.

Надо попробовать переход на линейное сканирование при определенных разменах сегмента (start, number). Попробовал, эффекта не получил. Вроде на группах порядка 100 элементов, небольшое улучшение чувствуется (не факт!), так что посталвил константу 100. 

Следующий эксперимент - запросы без загрузки и после перезапуска компьютера. Получилось 29 сек. / 100 запросов. Прямо точное "попадание" в вычисленное значение 100 * (10 мс. диска) * (24 раза обращение к диску за индексом и элементами).

Теперь надо добавлять шкалу.  

### 20190216 11:29
Рваный ритм моей нынешней жизни мешает, сильно мешает, сконцентрироваться на работе. Вот она и почти не двигается. Начал делать интерефейс Тургунды без View и Razor, но не доделал, потом поставил эксперимент делания сервиса - не доделал, потом сделал пототип JavaScript приложения - и опять не доделал!.. С чего начать? Главный "долг" перед пользователями - отсутствие новой версии пары редактор/вьюер, применительно к Открытому архиву.  Попробую поработать в этом направлении, тем более, есть что поодолжать. 

### 20190219 07:30
Я вчера вышел на то, что лэйаут нового решения не соответствует старому. Надо привести в соответствие. 

Продвинулся совсем чуть-чуть. Застрял на вычислении внутреннего формата. Например, Раскрываем запись. Ее формат задается и здесть вариаций нет. В записе есть поля, прямые ссылки и обратные ссылки. Прямые ссылки могут иметь варианты по типу записи элемента, куда ведет ссылка. Например, из отношения reflection ссылка in-doc может вести и в прото документ и в фото-видео-аудио. Надо проверять. То же самое, может быть и с обратными ссылками. Но там можно наладить безальтернативность. На всякий случай, стоит вычислять подформат по принципу: пройти direct или inverse, взять элементы record и взять тот, тип которого имеется в данном подзначении. 

### 20190220 11:29
Вчера "уперся в стенку". Выяснилось, что у меня какие-то проколы в семантике моей шаблонной системы. Или я что-то важное забыл... Проблема в альтернативах по типам и струкутрам записей. Шаблон диктует некоторое иерархическое построение выбранной части графа. Это построение видится в виде специального вида таблиц. Есть даже таблца с одним рядком... Проблема в том, что если есть альтернативные типы и соотвествующие им шаблоны, то непонятно что надо делать. 

Действительно, пусть есть запись и шаблон для этой записи. В шаблоне указываются поля, которые надо визуализировать в виде таблицы. Множественность вариантов полей пока опустим, будем считать, что есть только один вариант значения для каждого из полей, упомянутых в шаблоне. Определенность присутствует. Теперь рассмотрим прямые ссылки. Ссылаться по одному отношению запись может на другие записи разных типов. В шаблоне перечисляются варианты типов.  

Я до конца не понимаю ситуацию, но сформулировал некоторое предположение. Предположение заключается в том, что исходящая ссылка не предназначена для какого-то немедленного табличного оформления. Она лишь превращается в строку с гиперссылкой. А вот нажатие на гиперссылку возвращает ситуацию к стандартной, когда есть тип и есть значение записи и можно формировать каноническое представление. 

А вот в обратную сторону, в сторону inverse, вариантов быть не должно. Иначе трудно строить обратные таблицы. Посмотрю на текущий профиль или профили, используемые в Тургунде. Посмотрел. Вроде везде имеется единственность записи под направлением inverse, а под направлением direct есть варианты (по гео и документам).

Некоторая тонкость заключается в том, что "строковое" гиперзначение нужно делать на основе самостоятельного (другого) формата, а его пока нет. Но мы можем воспользоваться "стандартным" форматом:
```
<record type="системный объект"><field prop="name"/></record>
```
Даже не буду выписывать это решение, внесу его прямо в код. Удивительно, но именно это решение ранее было реализовано. Так что дело не в прямых ссылках, а в обратных отношениях. Проверил обратные отношения, вроде также правильно сделано. Попробую двигаться дальше. 

### 20190221 08:03
Я остановился перед критерием того, что нужно или не нужно использовать компактные представления или табличные представления. Ситуация связана с визуализацией группы обратных отношений, соответствующих одной обратной дуге. "Короткие" отношения sys->sys, типа "отец или мать", я уже давно не рассматриваю. Рассматриваю только псевдосущности. Если псевдосущность, то...

### 20190222 08:07
Вчера "запустил" демонстрацию фоток и пошел спать. По идее, "иконная" система должна обладать следующими свойствами: В режиме largeicons изображается некоторый имидж вместе с некоторой подписью. Если тип айтема photo-doc и есть поле uri, то изображение будет браться из этого uri. Иначе, а качестве имиджа будет взята дофолтная для типа иконка.

Уже сделал и фотодокумент. Правда был озадачен тем, что в старом переработанном массиве данных SypCassete, для всего есть только medium-размер. Это можно попробовать регулировать с контроллере Docs. Если нужен normal, а есть только medium, вставлять medium и наоборот. 

### 20190223 08:48
С Днем защитника Отечества! Я себя в достаточной мере ощущал и ощущаю защитником. Обучался, присягу принимал, сборы проходил, занимался критическими для страны технологиями, взаимодействовал с ВПК, обучал и обучаю студентов, школьников, аспирантов. Вот!

Такой мелкий вопрос как где разместить переключатель режима визуализации "панель/таблица", я не смог сраду ответить. Потом задумался об общих моментах, о пользовательских параметрах, о пользовательском состоянии (сессии). К этим вопросам можно будет вернуться позже, а пока сделаю переключение по-проще. Для начала попробую поместить его в переменные класса HomeController и посмотрю что получится. 

Вроде получилось и вроде смена состояния не мешает другим пользователям. Правда состояние "не держится" при уходе в каком-то стандартном направлении (без указания моды), но это мелочи. 

Итак, что надо сделать? Для оценки этого, попробую запустить новое решение на машине gea.

### 20190224 08:32
Уже четвертый день подряд начинаю работу в одно и то же время! С утра имеется энтузиазм, а потом он затухает. Вчера затух на задаче перехода к редактированию. Можно сказать, на авторизации. Можно сразу "окунаться" в cookies, а можно сделать сначала другое решение. Это состояние пользователя. Состояние закодировать строкой и передавать строку от вызова к вызову. В состояние можно "затолкать" имя пользователя, роль и т.д. 

Состояние не получается хранить оперативно, но можно передавать от одного кадра к другому. Состояние можно разбить на пользовательский код и собственно состояние и вторую часть хранить в базе данных. Или в cookies. Или можно попробовать сохранять состояние в сессии. Попробую этот последний вариант.  





